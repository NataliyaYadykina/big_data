{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Подготовка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nataliya\\AppData\\Local\\Temp\\ipykernel_17024\\1150078843.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачиваем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\imdb-user-reviews\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path('homework/hw1/imdb-user-reviews', 'imdb-user-reviews.csv')\n",
    "if not dataset_path.is_file():\n",
    "    od.download('https://www.kaggle.com/datasets/sadmadlad/imdb-user-reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте mapper и reducer, чтобы посчитать среднее и дисперсию оценок за фильм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация через цикл (предпогаем, что мы не знаем сколько у нас фильмов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "n, mean, M2 = 0, 0.0, 0\n",
    "# проходим циклом по содержимому загруженной папки\n",
    "for path in Path('imdb-user-reviews').glob('**/*'):\n",
    "    # если находим файл и этот файл .json:\n",
    "    if path.is_file() and path.suffix == '.json':\n",
    "        # открываем файл для чтения с кодировкой utf8, дав ему алиас f:\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            # сохраняем содержимое из json в виде словаря в info\n",
    "            info = json.load(f)\n",
    "        # сохраняем оценку, обращаясь к ней по соответствующему ключу\n",
    "        score = float(info['movieIMDbRating'])\n",
    "        # увеличиваем количество фильмов на 1\n",
    "        n += 1\n",
    "        # разница между оценкой и средним\n",
    "        delta = score - mean\n",
    "        # корректируем среднее, учитывая delta и количество фильмов\n",
    "        mean += delta / n\n",
    "        # корректируем среднее квадратичное\n",
    "        M2 += delta * (score - mean)\n",
    "\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе этого кода соберите mapper и reducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, которая будет применяться в map\n",
    "def mapper(path):\n",
    "    # если находим файл и этот файл .json:\n",
    "    if path.is_file() and path.suffix == '.json':\n",
    "        # открываем файл для чтения с кодировкой utf8, дав ему алиас f:\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            # сохраняем содержимое из json в виде словаря в info\n",
    "            info = json.load(f)\n",
    "        # возвращаем кортеж с оценкой, обращаясь к ней по соответствующему ключу\n",
    "        return (float(info['movieIMDbRating']), )\n",
    "\n",
    "\n",
    "# функция, которая будет применяться в reduce к элементам последовательности\n",
    "# на вход принимает 2 обязательных параметра\n",
    "# (первый - аккумулированное ранее значение, второй - следующий элемент последовательности)\n",
    "def reducer(score_data1, score_data2):\n",
    "    # если на вход пришли пустые значения обоих параметров:\n",
    "    if score_data1 is None and score_data2 is None:\n",
    "        # верннем None\n",
    "        return None\n",
    "    # если пустым на входе является только значение первого параметра\n",
    "    elif score_data1 is None:\n",
    "        # вернем значение второго параметра\n",
    "        return score_data2\n",
    "    # если пустым на входе является только значение второго параметра\n",
    "    elif score_data2 is None:\n",
    "        # вернем значение второго параметра\n",
    "        return score_data1\n",
    "    # если на входе оба значения не пустые:\n",
    "    else:\n",
    "        # инициализируем список оценок, пока он пуст\n",
    "        scores = []\n",
    "        # если размерность первого параметра reducer равна 1, мы на первой итерации reduce:\n",
    "        if len(score_data1) == 1:\n",
    "            # инициализируем искомые переменные, их значения пока не знаем, поэтому 0\n",
    "            n, mean, M2 = 0, 0.0, 0\n",
    "            # добавляем в список оценок первую оценку (нулевой элемент кортежа из mapper)\n",
    "            scores.append(score_data1[0])\n",
    "        # если размерность первого параметра reducer отлична от 1:\n",
    "        else:\n",
    "            # в искомые переменные записываем значения из предыдущей итерации reduce\n",
    "            n, mean, M2 = score_data1\n",
    "        # в список оценок добавляем очередное значения второго параметра reducer\n",
    "        scores.append(score_data2[0])\n",
    "        # проходим циклом по списку оценок:\n",
    "        for score in scores:\n",
    "            # корректируем количество\n",
    "            n += 1\n",
    "            # считаем разницу между оценкой и средним\n",
    "            delta = score - mean\n",
    "            # корректируем среднее, учитывая delta и количество фильмов\n",
    "            mean += delta / n\n",
    "            # корректируем среднее квадратичное\n",
    "            M2 += delta * (score - mean)\n",
    "        # возвращаем искомые значения n, mean, M2\n",
    "        return n, mean, M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce( # кумулятивно применяет функцию reducer к элементам итерируемой последовательности map, сводя её к единственному значению\n",
    "                reducer, # вернет искомые значения n, mean, M2\n",
    "                map( # вернет итерируемую последовательность кортежей с оценками фильмов для reduce\n",
    "                    mapper, # вернет кортеж с оценкой фильма из .json\n",
    "                    Path('imdb-user-reviews').glob('**/*') # итерируемое содержимое анализируемой папки (вложенные папки и файлы)\n",
    "                )\n",
    "            )\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 696 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "                reducer,\n",
    "                Parallel(n_jobs=2)( # параллельный запуск функции mapper с входным параметром path. Количество параллельных потоков = 2\n",
    "                    # количество итераций равно числу вложенных в целевую директорию папок (пропускаем) и файлов (обрабатываем .json)\n",
    "                    delayed(mapper)(path) for path in Path('imdb-user-reviews').glob('**/*')\n",
    "                )\n",
    "            )\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в данном случае распараллеливание задач не дало нам положительного эффекта.\n",
    "\n",
    "Времени на обработку было затрачено заметно больше.\n",
    "\n",
    "Мы имеем дело с небольшим набором данных, для обработки которого распараллеливание будет лишним\n",
    "\n",
    "и использование дополнительных функций приводит к увеличению времени обработки задач.\n",
    "\n",
    "Однако, попробуем заметно увеличить объем данных для обработки - в 100_000 раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03000000000032 1.0517128885774973\n",
      "CPU times: total: 4min 32s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "                reducer,\n",
    "                map(\n",
    "                    mapper,\n",
    "                    # увеличим наш список в 100_000 раз\n",
    "                    list(Path('imdb-user-reviews').glob('**/*')) * 100_000\n",
    "                )\n",
    "            )\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03000000000032 1.0517128885774973\n",
      "CPU times: total: 24.2 s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "                reducer,\n",
    "                Parallel(n_jobs=2)(\n",
    "                    delayed(mapper)(path) for path in list(Path('imdb-user-reviews').glob('**/*')) * 100_000\n",
    "                )\n",
    "            )\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы видим, что в результате распараллеливания задач мы заметно сократили время их обработки.\n",
    "\n",
    "Таким образом, при работе с большим набором данных будет оптимальным использование параллелизации.\n",
    "\n",
    "Попробуем увеличить количество параллельных потоков с 2 до 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03000000000032 1.0517128885774973\n",
      "CPU times: total: 37.2 s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "                reducer,\n",
    "                # Увеличим количество параллельных заданий до 6\n",
    "                Parallel(n_jobs=6)(\n",
    "                    delayed(mapper)(path) for path in list(Path('imdb-user-reviews').glob('**/*')) * 100_000\n",
    "                )\n",
    "            )\n",
    "print(mean, (M2 / n) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате увеличения количества параллельных потоков обработки данных время работы еще более существенно сократилось.\n",
    "\n",
    "Что также подтверждает оптимальность использования параллелизации выполнения задач при работе с большими наборами данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
